# Human-Centered, Intention-Aware Explanations for Code Generation

This repository contains a curated set of promptâ€“response experiments focused on understanding how current code generation models handle:

- Intent ambiguity
- Explanation clarity
- Scope control
- Human-aligned reasoning

## ğŸ“ Structure
- `prompts/` â€” categorized prompts for testing
- `responses/` â€” raw and annotated model outputs
- `evaluation/` â€” tracking sheet and scoring rubric
- `notebooks/` â€” optional analysis tools

## âœ… Goals
- Identify gaps in current models' ability to infer user intent
- Propose metrics for intent-alignment and human-centered explanations
- Showcase improvement opportunities in explainable code generation
